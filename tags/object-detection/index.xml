<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Object Detection on RainPot Blog</title>
    <link>/tags/object-detection/</link>
    <description>Recent content in Object Detection on RainPot Blog</description>
    
    <language>en</language>
    <lastBuildDate>Mon, 22 Jul 2019 00:00:00 +0000</lastBuildDate><atom:link href="/tags/object-detection/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>VisDrone2019记录</title>
      <link>/blog/visdrone2019/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/visdrone2019/</guid>
      <description>简单介绍本组VisDrone2019比赛Object Detection in Images任务所采用的算法方法。
Introduction RRNet 本次比赛提出并采用的网络框架为——RRNet，主要思想为将单阶段anchor-free算法(CenterNet)通过再次回归变为二阶段算法，通过再回归的方式让本就较精确的bbox更加精准。下图为网络框架图：
RRNet Struecture 网络主体为CenterNet,backbone为hourglass-104，两个hourglass block的输出全部参与分类及回归，Heatmap代表中心点的激活图，Size代表中心点所对应object长宽的激活图，输出的一共4个map分别进行focal loss和l1 loss的计算。此上为CenterNet的主要部分，接下来我们继续利用其输出的特征图，送入后面的Re-Regression Module进行二次回归。Re-Regression Module内部结构如下：
Re-Regression Module 通过CenterNet生成的Heatmap以及SIzemap，我们可以直接将其转换成为bbox，得到bbox之后(我们可以将其类比为faster-rcnn中RPN网络生成的候选框)，我们将这些候选区域送入ROI Align，进行再一次回归得到偏移量，将此偏移量加到原始bbox上的到修正后的输出。
Major features 除了再回归网络，我们还采用了以下一些方法让性能进一步提升：
method mAP 1.two-stage/multi-stage ↑2% 2.wh conv ↑0.3% 3.re-sample ↑1% 4.multiscale training/test ↑2% 5.sync training ↑1% 6.nms/soft nms ↑1% 7.KL-Loss (↑1%?) 8.warm up lr - 9.mix up - 10.ellipse gaussian - Details 1.two-stage/multi-stage two-stage便指再回归思想，对于进行多次回归(multi-stage)我们目前还没有进行实验。这个再回归让mAP提高了2%
2.wh conv 对于CenterNet中SIzemap的回归是单纯使用3x3卷积，我们认为这种卷积核并不能get到整个object的全部信息，从而以这种方式推理出object的长与宽是不合理的，于是我们采用1xk，kx1的卷积核分别推理object的宽和长，这样可能会获得更多有效信息。 此方法提升了0.3%的mAP。
wh conv 3.Data Augmentation 简单介绍一下数据增强方面所采用的一些方法
re-sample 我们发现对于people，pedestrian等小目标的类准确率非常低，于是采用了将hard-sample再次采样(复制)放到图上进行训练的方式。考虑到背景信息，我们首先使用在Cityscapes数据集上训好的deeplabv3以及图像腐蚀+中值滤波在我们自己的无人机数据集上分割出道路，这样复制出的人，自行车一类就可以让他们放在道路上而不是天上或楼上。
与此同时，由于镜头视角的缘故，在同一张图片中一个人的大小是不同的，直接复制出来填到任意一个地方也是不合理的，于是我们为了解决这个问题，首先在图中找到一个像素h(高度)最矮的一个人，同时再找三个h最高的人，建立一个人的高度h与图片像素位置H的线性关系，这样就可以根据要插入的位置，计算人应有的高度放进去也就不违和了。
multiscale training/test 此方法比较普遍，就不过多介绍了，基本对于任何算法(检测、分割)都可以提升最终的准确率。</description>
    </item>
    
  </channel>
</rss>
